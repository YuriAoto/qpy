qpy - the Pradipta's and Yuri's PYthon Queue system

Some general statements about the program

-> Initialize the qpy-master

How to initialize qpy-master

qpy-master needs to be initialized before submitting any job using qpy. 

The necessary command to initilize qpy-master is: 'qpy-master --cluster=' and the name of the cluster. qpy can only be used in the 'linux4' and 'hlrs' now. So use either of these two keywords for cluster. It is always best to make this command running in background. 

There are two different environment in which qpy can be used. The simpler one is to use the 'single-user' environment. This is the default one, so no different keywords to be used during the initialization of qpy-master. Here the user will be using the queing system alone without sharing the number of nodes that the user would assign for himself/herserlf.

The 'multiuser' environment can be used by initializing qpy-master with the option 'm' or '--multiuser'. This environment only works for linux4. Within this environment, some of the cores among the different 'orpheus' machines will be assigned to every users. So the user do not have to add nodes and assign maxJob to that node. Everything will be taken care by this 'multiuser' environment. 

Here are the different options that can be used while running qpy-master:
-v or --verbose :- to have some useful messages printed;
-m or --multiuser :- to set the multiuser environment;
-c or --cluster :- to specify the cluster (mandatory, there is no default);
-i or --initJobID :- to set the jod id for the first job


-> Using qpy

qpy is used to submit jobs from the main server (say 'linux4' and 'hlrs') and then the jobs are distributed to different nodes according the availability or the choices given by the user. It can handle jobs running in both single and multi processors. The distribution of jobs are different for 'linux4' and 'hlrs' cluter. For 'linux4', the submitted jobs are distributed to the defferent 'orpheus' nodes. The user, while using the 'single-user' environment , has to add the nodes and the number of cores he/she wants to use on that particular node before submitting the first job. The user, on the other hand, does not have to add any nodes or corersponding number of cores while using either the 'multi-user' enviroment in 'linux4' or 'hlrs' cluster. qpy allots a node itself along with the avaliable cores in these cases whenever it needs to submit any new job. 

The followings are the commands that are necessary to use qpy. While qpy-master is already running in the background, the user can user any of these commands as 'qpy [cmd]'

# sub

Submit any executable after the command 'qpy sub'. The output and the error file of running that particular script will be written in the files 'job_[jodid].out' and 'job_[jodid].err' respectively.

Submitting a serial job is the default one for this command. To submit a job that uses multi-processor, please add the information of number of processors (N) needed either by putting '-n N' between 'qpy sub' and the executable, or by adding '#QPY n_cores=N' in the script running. For the first case, do not put the option after the executable as it would then be considered as an option corresponding to the executable. 

qpy also check if enough memory is available in a node before starting a job there. The defualt memory it checks for availibility is 5 GB. If a job needs to use more memory (M) please add this information either by putting '-m M' between 'qpy sub' and the executable, or by adding '#QPY mem=M' in the script running.

# check

Check the status of all the submitted jobs. The command 'qpy check' gives the list of all jobs submitted along with the following information in this particular order: [jobid] [status] [submitted script] [working directory]. One can also check jobs of specific status which are: 'running', 'done', 'killed', 'undone' and 'queue' adding the keyword after 'qpy check'

# kill

Kill a particular jobs using the command 'qpy kill [jobid]'. One can also kill several jobs by providing a list of jobid's or a range of jobid's separated by '-'. Kill 'all'/'running' jobs or jobs in 'queue' by replacing the [jobid] with these keywords. 

# finish

If you feel like done using qpy or want to update the version and rerun it, please finish the existing qpy-master which is running in background using 'qpy finish'. If somehow the qpy-master crashe while using, please remove the '.port' file from the qpy directory before starting a new qpy session. 

# status

This command is mainly useful for the 'multi-user' environment. It writes elaborately the number of jobs running for each users and in each of the available nodes. 

# nodes

While working as a single user, it gives the number of cores being used by the user for each of the nodes that the user has added to use. It also provides the way to add or remove node by simple adding the name of the node after 'qpy nodes add/remove'. While using the 'multi-user' environment, this command gives the information about number of jobs running by all the users and how these jobs are distributed in each of the nodes. 

# maxJobs

This command set the maxJobs. The default of maxJobs is 20 for both linux4 (for single-user, not necessary at all for multiuser) and hlrs. The user can change the maxJobs for a particular node (any orpheus in linux4) by adding the name of a specific node at the end. e.g. 'qpy maxJobs 10 orpheus34' will change the maxJobs to 10 for orpheus34.

# config

This command gives informations about some of the variables in qpy. Feel free to check. It is quite self explanatory.One of the advanced feature of this command is to configure the format that 'qpy check' would follow. The default format that 'qpy check' uses to write all the jobs is '%j (%s):%c (on %n; wd: %d)\n'. It might seem little complicated, but it follows mainly these rules:
%j  -> job ID
%s -> job status
%c -> command you used to submit the job
%d -> working directory of your job
%n -> node allocated for your job
%N -> number of cores for your job.

The user can also change this format to a minimalistic one, by 'qpy config checkFMT %j:%s' or anything using the notations defined above. To check the current format, use the command 'qpy config checkFMT' and to change it to the default one, use 'qpy config checkFMT default'.

# clean

It cleane the list of jobs that one can see using 'qpy check'. The user can clean some specific jobs by adding the job id or the specific status of the job i.e. 'running', 'done', 'killed', 'undone' and 'queue' along with the command. User has to clean all the list before finishing qpy. 

# tutorial

This helps the user to understand a command. One can get the informations about any of the commands by adding its name after 'qpy tutorial'. 

-----------

Every command in qpy can be completed automatically by using the tab key. It also gives the possible next arguments which, we hope, would be very helpful for all the users :)
