#!/usr/bin/python
# qpy-master - set the main driver for qpy
#
# 29 May 2015 - Pradipta and Yuri
from multiprocessing.connection import Listener
from multiprocessing.connection import Client
import threading
from time import sleep, time
from collections import deque
from Queue import Queue
import re
import subprocess
import sys
import os
import random
from optparse import OptionParser,OptionError

from qpy_general_variables import *

class ParseError(Exception):
    pass

parser = OptionParser()
parser.add_option("-v", "--verbose",
                  action="store_true", dest="verbose", default=False,
                  help="print messages")

parser.add_option("-m", "--multiuser",
                  action="store_true", dest="multiuser", default=False,
                  help="set to multiuser behaviour")

parser.add_option("-s", "--saveMessages",
                  action="store_true", dest="saveMessages", default=False,
                  help="set to multiuser behaviour")

parser.add_option("-c", "--cluster",
                  dest="cl",
                  help="the cluster (linux4 and hlrs available)")

parser.add_option("-i", "--iniJobID",
                  dest="iniJobID",
                  help="the first jobID to be used")


(options, args) = parser.parse_args()

verbose = options.verbose
multiuser = options.multiuser
saveMessages = options.saveMessages
cluster = options.cl
ini_job_ID = options.iniJobID

if (ini_job_ID):
    try:
        ini_job_ID = int( ini_job_ID)
    except:
        sys.exit( 'The option --iniJobID receive an integer as argument.')
else:
    ini_job_ID = None

if (not (cluster)):
    sys.exit( 'Give the --cluster option.')

if (cluster != "hlrs" and cluster != "linux4"):
    sys.exit( 'Cluster must be hlrs or linux4.')

if (multiuser and cluster == "hlrs"):
    sys.exit( 'Multiuser not available on hlrs.')

dyn_nodes = cluster == "hlrs"

max_node_time = 1814400
min_working_time = 600
max_working_time = 604800

multiuser_waiting_time = 15
conn_multiuser_at = 300

max_nodes_default = -1
if (dyn_nodes):
    max_nodes_default = 3

home_dir = os.environ['HOME']
qpy_dir = os.path.dirname( os.path.abspath( __file__))
user = os.environ['USER']

source_these_files = ['~/.bash_profile']

port_file = qpy_dir + '/.port'
cur_nodes_file = qpy_dir + '/.current_nodes'
known_nodes_file = qpy_dir + '/.known_nodes'
jobID_file = qpy_dir + '/.next_jobID'

multiuser_address = 'localhost'
multiuser_key = 'zxcvb'
multiuser_port = 9999

if (saveMessages):
    multiuser_messages = deque(maxlen=25)

if (not( os.path.isfile( known_nodes_file))):
    f = open( known_nodes_file, 'w')
    f.close()

if (not( os.path.isfile( jobID_file))):
    f = open( jobID_file, 'w')
    f.write( '1')
    f.close()

if (os.path.isfile( port_file)):
    sys.exit( 'A port file was found. Is there a qpy-master instance running?')

random.seed()
port = random.randint( 10000, 20000 )
f = open( port_file, 'w', 0)
f.write( str( port))
f.close()



# Attempt to connect to qpy-multiuser
class try_multiuser_connection( threading.Thread):
    def __init__( self):
        threading.Thread.__init__( self)
        self.conn = None
    def run( self):
        self.conn = Client( (multiuser_address, multiuser_port), authkey=multiuser_key)


# Send arguments to qpy-multiuser
def send_multiuser_arguments( option, arguments):
    M = try_multiuser_connection()
    M.start()
    n = 0
    waiting = 60
    while (M.is_alive()):
        n += 1
        if (n == waiting):
            kill_conn = Listener(( multiuser_address, multiuser_port), authkey = multiuser_key)
            client = kill_conn.accept()
            kill_conn.close()
            return None
        sleep( 0.05)
    conn = M.conn
    conn.send( (option, arguments))
    msg_back = conn.recv()
    conn.close()
    if (saveMessages):
        if (not(multiuser_messages) or ((option, arguments), msg_back) != multiuser_messages[-1][0]):
            multiuser_messages.append( [ ((option, arguments), msg_back), 1])
        elif (multiuser_messages[-1][1] < 10):
            multiuser_messages[-1][1] += 1
    return msg_back


# Check if the <command> sent by ssh to <address> return the <exp_out> message without errors
def is_ssh_working( address, command, exp_out):
    ssh = subprocess.Popen(["ssh", "-o", "StrictHostKeyChecking=no", address, command],
                             shell=False,
                             stdout=subprocess.PIPE,
                             stderr=subprocess.PIPE)
    ssh_stdout = ssh.stdout.readlines()
    ssh_stderr = ssh.stderr.readlines()
    if (verbose):
        print "is_ssh_working stdout:", ssh_stdout
        print "is_ssh_working stderr:", ssh_stderr
    error = False
    for i in ssh_stderr:
        if ('No route to host' in i or 'Connection refused' in i or 'Could not resolve hostname' in i):
            error = True
    success = False
    for i in ssh_stdout:
        if (exp_out in i):
            success = True
    return success and not( error)


def get_plural( word_s, stuff):
    """ Cosmetic function: get the plural

    @param word_s touple or list with (singular_case, plural_case)
    @param stuff list of strings or a positive int
    @return tuple (correct_case, Predicate or listing)
    example: get_plural(("job","jobs"),0) =>("jobs", "No")
             get_plural(("job","jobs"),["queued", "running", "killed"]) =>("jobs", "queued, running and killed")
    """
    if (isinstance(stuff,list)):
        if (len(stuff)==0):
            return (word_s[1], 'No')
        elif (len(stuff)==1): 
            return (word_s[0], str(stuff[0]))
        elif (len(stuff) > 1):
            ret=", ".join(stuff[:-1])+" and "+stuff[-1]
            return (word_s[1], ret)
        else:
            #Ok, this case would be really weird
            raise Exception("get_plural: negative list length??  ????????"+str(word_s)+str(stuff))
    elif (isinstance(stuff, int)):
        if (stuff == 0 ):
            return (word_s[1], 'No')
        elif (stuff == 1):
            return (word_s[0], str(stuff))
        elif (stuff > 1):
            return (word_s[1], str(stuff))
        else:
            raise Exception("get_plural: negative amount??"+str(word_s)+str(stuff))
    else:
        raise Exception("get_plural:stuff neither int nor list??"str(type(stuff)))



# Allocate a node. Specific for ASES
def node_alloc():
    queue_script = 'qpy --alloc ' + str( max_node_time)
    command = 'salloc -N1 -t 21-0 -K -A ithkoehn ' + queue_script + ' &'
    salloc = subprocess.Popen(command,
                              shell=True,
                              stdout=subprocess.PIPE,
                              stderr=subprocess.PIPE)
    salloc_stderr = salloc.stderr.readline()
    re_res = re.match('salloc: Granted job allocation (\d+)', salloc_stderr)
    try:
        job_id = re_res.group(1)
    except:
        if (verbose):
            print 'Error in node allocation: ' + salloc_stderr
        return None
    command = 'squeue | grep ' + job_id
    squeue = subprocess.Popen(command,
                              shell=True,
                              stdout=subprocess.PIPE,
                              stderr=subprocess.PIPE)
    saloc_stdout = squeue.stdout.readline().split()
    node = saloc_stdout[-1]
    while (not( is_ssh_working( node, 'source ~/.bash_profile; qpy --init', 'Success on qpy init!'))):
        if (verbose):
            print "Waiting node initialization: " + node
        sleep( 10)
    if (verbose):
        print 'Node ' + node + ' allocated.'
    return (job_id, node)


# Deallocate a node. Specific for ASES
def node_dealloc( node_id, alloc_id):
    term_script = 'source ~/.bash_profile; qpy --term'
    dealloc = subprocess.Popen(["ssh", "-o", "StrictHostKeyChecking=no", node_id, term_script],
                               shell=False,
                               stdout=subprocess.PIPE,
                               stderr=subprocess.PIPE)
    if (verbose):
        print "node_dealloc stdout:", dealloc.stdout.readlines()
        print "node_dealloc stderr:", dealloc.stderr.readlines()
    command = 'scancel ' + alloc_id
    dealloc = subprocess.call( command, shell=True)
    if (verbose):
        print 'Node ' + node_id + ' deallocated.'


# Check output
#
class out_err_check( threading.Thread):
    
    def __init__( self, ssh, out_or_err, out_err_file):
        threading.Thread.__init__( self)
        self.ssh = ssh
        self.out_or_err = out_or_err
        self.file = out_err_file
        self.file_lock = threading.RLock()

    def run( self):

        if (self.out_or_err):
            for c in iter( lambda: self.ssh.stdout.read(1), ''):
                self.file_lock.acquire()
                self.file.write(c)
                self.file_lock.release()
        else:
            for c in iter( lambda: self.ssh.stderr.read(1), ''):
                self.file_lock.acquire()
                self.file.write(c)
                self.file_lock.release()


job_status = ['queue',   # 0
              'running', # 1
              'done',    # 2
              'killed',  # 3
              'undone']  # 4

    

# A Job
#
class JOB( threading.Thread):
    
    def __init__( self, jobID, job_info):
        threading.Thread.__init__( self)
        self.ID = jobID
        self.info = job_info
        self.n_cores = 1
        self.mem = 5.0
        self.node = None
        self.status = 0
        self.err_msg = ''
        self.set_parser()

    def set_parser(self):
        """creates a parser for the flags that can be set for a job"""
        #I would like to supply a help option, but at the moment I don't know, how to let it print, where I want
        parser=OptionParser(add_help_option=False)
        parser.add_option("-n","--cores", dest="cores", help="set the number of cores", default="1")
        parser.add_option("-m","--mem","--memory",dest="memory",help="set the memory in GB", default="5")
        #    parser.add_option("-h","--help"...)
        self.parser=parser
 

    def run( self):
        command =  'export QPY_JOB_ID=' + str( self.ID) + '; '
        command += 'export QPY_NODE=' + str( self.node.node_id) + '; '
        command += 'export QPY_N_CORES=' + str( self.n_cores) + '; '
        for sf in source_these_files:
            command += 'source ' + sf + '; '
        command += 'cd ' + self.info[1] + '; ' 
        command += self.info[0]
        ssh = subprocess.Popen(["ssh", self.node.node_id, command],
                               shell=False,
                               stdout=subprocess.PIPE,
                               stderr=subprocess.PIPE)

        def out_or_err_name(job, postfix):
            assert(postfix in ['.out', '.err'])
            return '{dir}/job_{id}{postfix}'.format(dir=job.info[1], id=str(job.ID), postfix=postfix )

        f_out = open( out_or_err_name(self, '.out'), 'w', 0)
        f_err = open( out_or_err_name(self, '.err'), 'w', 0)

        err_chk = out_err_check( ssh, False, f_err)
        err_chk.start()
        out_chk = out_err_check( ssh, True, f_out)
        out_chk.start()

        err_chk.join()
        out_chk.join()

        f_err.close()
        f_out.close()

    def parse_options( self):
        
        options,command=self.parser.parse_args( self.info[0].split())
        try:
            self.n_cores=int(options.cores)
            self.mem = int(options.memory)
        except AttributeError, TypeError as ex:
            raise ParseError("something went wrong. please contact the qpy-team\n"+ex.message)
        except ValueError:
            raise ParseError("please supply only full numbers for memory or number of cores")
        self.info[0] = ' '.join(command)

        first_arg = command[0]
        if (first_arg[0] == '/'):
            script_name = first_arg
        else:
            script_name = self.info[1] + '/' + first_arg

        if (os.path.isfile( script_name)):
            with open( script_name, 'r') as f:
                for line in f:
                    if (re.match( '#QPY', line)):
                        option_found=False
                        re_res = re.search( 'n_cores=(\d+)', line)
                        try:
                            self.n_cores = int(re_res.group(1))
                            option_found=True
                        except TypeError:
                            pass
                        except ValueError:
                            raise ParseError("Invalid Value for n_cores found")
                        re_res = re.search( 'mem=(\d+)', line)
                        try:
                            self.mem = int(re_res.group(1))
                            option_found=True
                        except TypeError:
                            pass
                        except ValueError:
                            raise ParseError("Invalid Value for mem found")
                        if (not option_found):
                            raise ParseError("QPY directive found, but no options supplied."/
                                             "Please remove the #QPY directive if you don't want to supply a valid option")
        else:
            raise ParseError("Submission script seems not to exist")

    # return a boolean, indicating whether this job obbeys the dictionary pattern or not
    # empty pattern means that everthing is required
    def asked( self, pattern):
        req = True
        for k in pattern:
            if (k == 'status'):
                req = job_status[self.status] in pattern[k]
        return req

class job_collection():
    
    def __init__( self):
        self.lock = threading.RLock()        
        self.all = []
        self.queue = []
        self.running = []
        self.done = []
        self.killed = []
        self.undone = []

        self.queue_size = 0

        self.Q = deque()
        self.Q_lock = threading.RLock()

# A node.
#
class NODE( threading.Thread):

    def __init__( self, max_jobs, *args):
        threading.Thread.__init__( self)

        if (dyn_nodes):
            new_node = node_alloc()
        else:
            if ( not(args)):
                sys.exit( 'Internal error: no arguments in node allocation')
            new_node = ( None, args[0])
        try:
            self.alloc_id = new_node[0]
            self.node_id = new_node[1]
        except:
            self.alloc_id = None
            self.node_id = None

        self.init_time = time()
        self.max_jobs = max_jobs
        self.n_jobs = 0
        self.queue = Queue()
        
    def run( self):

        while True:
            new_job = self.queue.get()
            if (verbose):
                print 'Node ' + str( self.node_id) + ': new job.'

            if ( isinstance( new_job, str)):
                if ( new_job == 'kill'):
                    break

            new_job.node = self
            new_job.status = 1
            new_job.start()
                
            sleep(1)

        if ( self.alloc_id != None):
            node_dealloc( self.node_id, self.alloc_id)
        
        if (verbose):
            print 'Node ' + str( self.node_id) + ' done.'
            

# Control jobs subimission
# 
#
class submission_control( threading.Thread):
    def __init__( self):
        threading.Thread.__init__( self)
        self.live = True
        self.node_list = []
        self.max_nodes = max_nodes_default
        if (multiuser):
            self.max_jobs_default = -1
        else:
            self.max_jobs_default = 20
        self.jobs = job_collection()
        self.multiuser_cur_jobs = []
        self.skip_job_sub = 0

    def write_nodes( self):
        with  open( cur_nodes_file, 'w') as f:
            for node in self.node_list:
                f.write( node.node_id + '\n')

    def write_new_known_node( self, new_node):
        with open( known_nodes_file, 'r') as f:
            known_nodes = []
            for node in f:
                known_nodes.append( node.strip())

        if (not( new_node in known_nodes)):
            with open( known_nodes_file, 'a') as f:
                f.write( new_node + '\n')
            
    def run( self):
        if (not( multiuser)):
            self.write_nodes()
        n_time_multiuser = 0
        multiuser_is_alive = True
        while self.live:

            # Connect with qpy-multiuser
            if (multiuser and n_time_multiuser == 0):
                msg_back = send_multiuser_arguments( MULTIUSER_USER, [user])
                if (msg_back == None):
                    multiuser_is_alive = False
                else:
                    multiuser_is_alive = True
                    if (not( isinstance( msg_back[1], list))):
                        msg_back = send_multiuser_arguments( MULTIUSER_USER, (user, self.multiuser_cur_jobs))
                if (verbose):
                    print "Checking multiuser: ", msg_back
                n_time_multiuser = conn_multiuser_at
            else:
                n_time_multiuser -= 1

            
            # Check finished jobs
            self.jobs.lock.acquire()
            i = 0
            while (i < len( self.jobs.running)):
                job = self.jobs.running[i]
                if (not job.is_alive()):
                    job.status = 2
                    self.jobs.running.remove( job)
                    self.jobs.done.append( job)
                    job.node.n_jobs -= job.n_cores
                    self.skip_job_sub = 0

                    if (multiuser and multiuser_is_alive):
                        self.multiuser_cur_jobs.remove( [job.ID, job.node.node_id, job.n_cores])
                        multiuser_args = (user, job.ID, self.jobs.queue_size)
                        msg_back = send_multiuser_arguments( MULTIUSER_REMOVE_JOB, multiuser_args)
                        if (msg_back == None):
                            multiuser_is_alive = False
                        if (verbose):
                            print 'Multiuser message (removing a job): ', msg_back
                else:
                    i += 1
            self.jobs.lock.release()


            # Dealloc the non-used node
            if (dyn_nodes):
                cur_time = time()
                for node in self.node_list:
                    if (not( node.n_jobs) and (cur_time - node.init_time) > min_working_time):
                        node.queue.put( 'kill')
                        self.node_list.remove( node)


            # Send a job, if there is space
            if (self.skip_job_sub <= 0):
                self.jobs.Q_lock.acquire()
                queue_has_jobs = len( self.jobs.Q) != 0
                if (queue_has_jobs):
                    next_jobID = self.jobs.Q[-1].ID
                    next_Ncores = self.jobs.Q[-1].n_cores
                    next_mem = self.jobs.Q[-1].mem
                    best_node = None
                    if (multiuser and multiuser_is_alive):
                        multiuser_args = (user, next_jobID, next_Ncores, next_mem, self.jobs.queue_size)
                        msg_back = send_multiuser_arguments( MULTIUSER_REQ_CORE, multiuser_args)
                        if (msg_back == None):
                            multiuser_is_alive = False
                            continue
                        if (verbose):
                            print 'Multiuser message (sending job): ', msg_back
                        if (msg_back[0] == 0):
                            self.multiuser_cur_jobs.append( [next_jobID, msg_back[1], next_Ncores])
                            node_found = False
                            for node in self.node_list:
                                if (msg_back[1] == node.node_id):
                                    best_node = node
                                    node_found = True
                                    break
                            if (not( node_found)):
                                best_node = NODE( -1, msg_back[1])
                                best_node.start()
                                self.node_list.append( best_node)
                        else:
                            self.skip_job_sub = 300
                    else:
                        best_free = 0
                        cur_time = time()
                        for node in self.node_list:
                            free = node.max_jobs - node.n_jobs
                            if (free > best_free):
                                if (not( dyn_nodes) or (cur_time - node.init_time) < max_working_time):
                                    best_node = node
                                    best_free = free
                        if (best_node == None and len( self.node_list) < self.max_nodes):
                            best_node = NODE( self.max_jobs_default)
                            if (best_node.node_id):
                                best_node.start()
                                sub_ctrl.node_list.append( best_node)
                            else:
                                best_node.start()
                                best_node.queue.put( 'kill')
                                best_node = None
                                self.skip_job_sub = 180
                    if (best_node != None):
                        if (verbose):
                            print "submission_control: putting job"
                        job = self.jobs.Q.pop()
                        best_node.queue.put( job)
                        best_node.n_jobs += job.n_cores
                        self.jobs.lock.acquire()
                        self.jobs.queue.remove( job)
                        self.jobs.queue_size -= 1
                        self.jobs.running.append( job)
                        self.jobs.lock.release()
                self.jobs.Q_lock.release()

            else:
                self.skip_job_sub -= 1
                if (verbose):
                    print "Skipping job submission: " + str( self.skip_job_sub)

            sleep( 1)


# formating a list of jobs:
# TODO: implement an option that gives the user supplied informations
def format_job( job):
    job_str = str( job.ID) + ' (' + job_status[job.status] + '):' + job.info[0] + ' (wd: ' + job.info[1] + ')\n'
    return job_str


# return string with information on required jobs, defined by pattern
def check_jobs( jobs, pattern):
    asked_jobs = []
    jobs.lock.acquire()
    for job in jobs.all:
        if (job.asked( pattern)):
            asked_jobs.append( job)
    jobs.lock.release()

    # TODO: sort - implement based on required info

    req_jobs = ''
    for job in asked_jobs:
        j_str = format_job( job)
        req_jobs += j_str

    return req_jobs


# Kill job
def job_kill( job, sub_ctrl):
    kill_command = 'source ~/.bash_profile; qpy --jobkill ' + str( job.ID)
    kill_p = subprocess.Popen(["ssh", "-o", "StrictHostKeyChecking=no", job.node.node_id, kill_command],
                              shell=False,
                              stdout=subprocess.PIPE,
                              stderr=subprocess.PIPE)
    job.status = 3
    job.node.n_jobs -= job.n_cores
    if (verbose):
        print "Killing job " + str( job.ID) + ' on node ' + job.node.node_id
        print "job_kill stdout: ", kill_p.stdout.readlines()
        print "job_kill stderr: ", kill_p.stderr.readlines()

    if (multiuser):
        multiuser_args = (user, job.ID, sub_ctrl.jobs.queue_size)
        msg_back = send_multiuser_arguments( MULTIUSER_REMOVE_JOB, multiuser_args)
        if (verbose):
            if (msg_back == None):
                print 'Multiuser seems not to be running.'
            else:
                print 'Multiuser message (killing a job): ', msg_back[1]
        sub_ctrl.multiuser_cur_jobs.remove( [job.ID, job.node.node_id, job.n_cores])

# Get job from client and send it for submission
# message from client must be:
#   (job_type, arguments)
# where:
#   job_type is
#       JOBTYPE_SUB     - submit a job                           (sub)
#       JOBTYPE_CHECK   - check the jobs                         (check)
#       JOBTYPE_KILL    - kill a job                             (kill)
#       JOBTYPE_FINISH  - kill the master                        (finish)
#       JOBTYPE_NODES   - change max_nodes or add/remove a node  (nodes)
#       JOBTYPE_MAXJOBS - change max_jobs                        (njobs)
#       JOBTYPE_CONFIG  - show config                            (config)
#       JOBTYPE_CLEAN   - clean finished jobs                    (clean)
#
#   the arguments are option dependent. See below
#
def handle_client( sub_ctrl, jobId):
    if (verbose):
        print "handle_client: ready"
    server_master = Listener(( "localhost", port), authkey = 'qwerty')
    while True:
        client_master = server_master.accept()
        (job_type, arguments) = client_master.recv()
        if (verbose):
            print "Received: " + str(job_type) + " -> " + str(arguments)
            
        # Send a job
        # arguments = the job info (see JOB.info)
        if (job_type == JOBTYPE_SUB):
            new_job = JOB( jobId, arguments)
            try:
                new_job.parse_options()
                sub_ctrl.jobs.lock.acquire()
                sub_ctrl.jobs.all.append( new_job)
                sub_ctrl.jobs.queue.append( new_job)
                sub_ctrl.jobs.queue_size += 1
                sub_ctrl.jobs.lock.release()
                sub_ctrl.jobs.Q_lock.acquire()
                sub_ctrl.jobs.Q.appendleft( new_job)
                sub_ctrl.jobs.Q_lock.release()
                client_master.send( 'Job ' + str(jobId) + ' received.\n')
                jobId += 1
                with open( jobID_file, 'w') as f:
                    f.write( str( jobId))
            except ParseError as ex:
                client_master.send( 'Job ' + str(jobId) + ' rejected.\n'+ex.message)
                
                

        # Check jobs
        # arguments: a dictionary, indicating patterns (see JOB.asked)
        elif (job_type == JOBTYPE_CHECK):
            client_master.send( check_jobs( sub_ctrl.jobs, arguments))

        # Kill a job
        # arguments = a list of jobIDs and status (all, queue, running)
        elif (job_type == JOBTYPE_KILL):

            kill_q = False
            kill_r = False
            if ('all' in arguments):
                kill_q = True
                kill_r = True
            if ('queue' in arguments):
                kill_q = True
            if ('running' in arguments):
                kill_r = True

            for st in ['all', 'queue', 'running']:
                while (st in arguments):
                    arguments.remove( st)

            sub_ctrl.jobs.lock.acquire()
            sub_ctrl.jobs.Q_lock.acquire()
            n_kill_q = 0
            to_remove = []
            for job in sub_ctrl.jobs.queue:
                if (job.ID in arguments or kill_q):
                    to_remove.append( job)
            for job in to_remove:
                job.status = 4
                sub_ctrl.jobs.queue.remove( job)
                sub_ctrl.jobs.queue_size -= 1
                sub_ctrl.jobs.undone.append( job)
                sub_ctrl.jobs.Q.remove( job)
                n_kill_q += 1
            sub_ctrl.jobs.Q_lock.release()
            n_kill_r = 0
            to_remove = []
            for job in sub_ctrl.jobs.running:
                if (job.ID in arguments or kill_r):
                    to_remove.append( job)
            for job in to_remove:
                job_kill( job, sub_ctrl)
                sub_ctrl.jobs.running.remove( job)
                sub_ctrl.jobs.killed.append( job)
                n_kill_r += 1
            sub_ctrl.jobs.lock.release()

            if (n_kill_q + n_kill_r):
                sub_ctrl.skip_job_sub = 0

            msg = ''
            if (n_kill_q):
                plural = get_plural( ('job', 'jobs'), n_kill_q)
                msg += plural[1] + ' ' + plural[0] + ' removed from the queue.\n'
            if (n_kill_r):
                plural = get_plural( ('job', 'jobs'), n_kill_r)
                msg += plural[1] + ' ' + plural[0] + ' killed.\n'

            if (not( msg)):
                msg = 'Nothing to do: required jobs not found.\n'
            client_master.send( msg)

        # Finish the master execution
        # argumets: no arguments
        if (job_type == JOBTYPE_FINISH):
            sub_ctrl.jobs.lock.acquire()
            if (sub_ctrl.jobs.all):
                client_master.send( 'There are unfinished or unanalysed jobs.\n')
            else:
                for node in sub_ctrl.node_list:
                    node.queue.put( 'kill')
                client_master.send( 'Stopping qpy-master driver.\n')
                sub_ctrl.live = False
                break
            sub_ctrl.jobs.lock.release()

        # Change maximum number of nodes or add/remove nodes
        # arguments: empty list, to show the nodes
        #        or  an integer, to change the maximum number of nodes
        #        or  a list: [<add/remove/forceRemove>, <'all'>, <node_1>, <node_2>, ]
        elif (job_type == JOBTYPE_NODES):
            msg = ''
            if (arguments and not( multiuser)):
                if (dyn_nodes):
                    try:
                        sub_ctrl.max_nodes = int( arguments)
                        msg = 'Maximum number of nodes changed to ' + str( arguments) + '.\n'
                    except:
                        msg = 'This should be an integer: ' + str( arguments) + '.\n'
                else:
                    if (arguments[0] == 'remove' or arguments[0] == 'forceRemove'):
                        nodes_OK = []
                        nodes_BAD = []
                        arguments.remove( arguments[0])
                        remove_all = 'all' in arguments
                        while ('all' in arguments):
                            arguments.remove( 'all')

                        i_n = 0
                        while (i_n < len( sub_ctrl.node_list)):
                            node = sub_ctrl.node_list[i_n]
                            removed = False
                            if (node.node_id in arguments or remove_all):
                                if (node.n_jobs == 0 or arguments[0] == 'forceRemove'):
                                    if (node.node_id) in arguments:
                                        arguments.remove( node.node_id)
                                    nodes_OK.append( node.node_id)
                                    node.queue.put( 'kill')
                                    sub_ctrl.node_list.remove( node)
                                    removed = True
                                elif (node.n_jobs > 0):
                                    nodes_BAD.append( node.node_id)
                                    
                            if (not( removed)):
                                i_n += 1

                        msg = ''
                        if (nodes_OK):
                            plural = get_plural( ('Node', 'Nodes'), nodes_OK)
                            msg += plural[0] + ' ' + plural[1] + ' removed.\n'
                        if (nodes_BAD):
                            plural = get_plural( (('Node', 'has'), ('Nodes', 'have')), nodes_BAD)
                            msg += plural[0][0] + ' ' + plural[1] + ' ' + plural[0][1] + ' running jobs. Use forceRemove.\n'
                        if (arguments):
                            plural = get_plural( ('Node', 'Nodes'), arguments)
                            msg += plural[0] + ' ' + plural[1] + ' not found.\n'

                    elif (arguments[0] == 'add'):
                        nodes_OK = []
                        nodes_BAD = []
                        arguments.remove( arguments[0])
                        i = 0
                        while (i < len( arguments)):
                            n_name = arguments[i]
                            is_new_node = True
                            for node in sub_ctrl.node_list:
                                if (node.node_id == n_name):
                                    is_new_node = False
                                    break
                            if (is_new_node):
                                arguments.remove( n_name)
                                if (is_ssh_working( n_name, 'hostname', n_name)):
                                    new_node = NODE( sub_ctrl.max_jobs_default, n_name)
                                    new_node.start()
                                    sub_ctrl.node_list.append( new_node)
                                    nodes_OK.append( n_name)
                                    sub_ctrl.write_new_known_node( n_name)
                                else:
                                    nodes_BAD.append( n_name)
                            else:
                                i += 1

                        msg = ''
                        if (nodes_OK):
                            plural = get_plural( ('Node', 'Nodes'), nodes_OK)
                            msg += plural[0] + ' ' + plural[1] + ' added.\n'
                        if (arguments):
                            plural = get_plural( ('Node', 'Nodes'), arguments)
                            msg += plural[0] + ' ' + plural[1] + ' already added.\n'
                        if (nodes_BAD):
                            plural = get_plural( ('node', 'nodes'), nodes_BAD)
                            msg += 'Connection on ' + plural[0]+ ' ' + plural[1] + ' seems not to work.\n'

                    sub_ctrl.write_nodes()
                    
            else:
                if (multiuser):
                    msg = 'Nodes under multiuser control:\n'
                    if (arguments and arguments[0]=='full'):
                        msg_back = send_multiuser_arguments( MULTIUSER_STATUS, ())
                        if (msg_back == None):
                            msg += 'qpy-multiuser seems not to be running. Contact the qpy-team.\n'
                        else:
                            msg += msg_back[1] + '\n'
                        for node in sub_ctrl.node_list:
                            msg = msg.replace(node.node_id + ': ', node.node_id + ': ' + str( node.n_jobs) + '/')
                    else:
                        for node in sub_ctrl.node_list:
                            msg += node.node_id + ': ' + str( node.n_jobs) + '\n'
                else:
                    for node in sub_ctrl.node_list:
                        msg += node.node_id + ': ' + str( node.n_jobs) + '/' + str( node.max_jobs) + '\n'

            client_master.send( msg)

        # Change maximum number of jobs
        # arguments: a list: [<new_maxJob>, <node_1>, <node_2>, ...]. Change all nodes if no nodes were given
        elif (job_type == JOBTYPE_MAXJOBS):
            if (multiuser):
                msg = 'Nodes under multiuser control:\n'
                msg_back = send_multiuser_arguments( MULTIUSER_STATUS, ())
                if (msg_back == None):
                    msg += 'qpy-multiuser seems not to be running. Contact the qpy-team.\n'
                else:
                    msg += msg_back[1] + '\n'
                    for node in sub_ctrl.node_list:
                        msg = msg.replace(node.node_id + ': ', node.node_id + ': ' + str( node.n_jobs) + '/')
            else:
                new_maxJob = arguments[0]
                if (len( arguments) == 1):
                    sub_ctrl.max_jobs_default = new_maxJob
                    for node in sub_ctrl.node_list:
                        node.max_jobs = new_maxJob
                    msg = 'Maximum number of jobs changed to ' + str( new_maxJob) + '.\n'
                else:
                    default_changed = False
                    if ('maxJob_default' in arguments[1:]):
                        sub_ctrl.max_jobs_default = new_maxJob
                        default_changed = True
                    while ('maxJob_default' in arguments):
                        arguments.remove( 'maxJob_default')
                    nodes_OK = []
                    nodes_BAD = []
                    for node_name in arguments[1:]:
                        not_changed = True
                        for node in sub_ctrl.node_list:
                            if (node.node_id == node_name):
                                node.max_jobs = new_maxJob
                                not_changed = False
                                nodes_OK.append( node_name)
                                break
                        if (not_changed):
                            nodes_BAD.append( node_name)

                    msg = ''
                    if (default_changed):
                        msg += 'Defaut value for maximum number of jobs changed to ' + str( new_maxJob) + '.\n'
                    if (nodes_OK):
                        plural = get_plural( ('node', 'nodes'), nodes_OK)
                        msg += 'Maximum number of jobs for ' + plural[0] + ' ' + plural[1] + ' changed to ' + str( new_maxJob) + '.\n'
                    if (nodes_BAD):
                        plural = get_plural( ('Node', 'Nodes'), nodes_BAD)
                        msg += plural[0]+ ' ' + plural[1] + ' not found.\n'

            client_master.send( msg)

        # Show current configuration
        # arguments: no arguments
        elif (job_type == JOBTYPE_CONFIG):
            cur_conf = ''
            if (not( multiuser)):
                cur_conf += 'max_jobs         = ' + str( sub_ctrl.max_jobs_default) + '\n'
            if (dyn_nodes):
                cur_conf += 'using dynamic node allocation\n'
                cur_conf += 'max_nodes        = ' + str( sub_ctrl.max_nodes) + '\n'
                cur_conf += 'max_node_time    = ' + str( max_node_time) + '\n'
                cur_conf += 'min_working_time = ' + str( min_working_time) + '\n'
                cur_conf += 'max_working_time = ' + str( max_working_time) + '\n'
            if (multiuser):
                cur_conf += 'Nodes under multiuser control.\n'
                if (saveMessages):
                    cur_conf += 'Last multiuser messages:\n'
                    for msg in multiuser_messages:
                        cur_conf += ' ' + str( msg[0][0][0]) + ', ' + str( msg[0][0][1]) + ': ' + str( msg[0][1][0]) + ', ' + repr( msg[0][1][1])
                        if (msg[1] > 1):
                            cur_conf += ' (' + str(msg[1]) + 'x)'
                        cur_conf += '\n'

            client_master.send( cur_conf)

        # Clean finished jobs
        # arguments = a list of jobIDs and status (all, done, killed, undone)
        elif (job_type == JOBTYPE_CLEAN):
            n_jobs = 0
            for i in arguments:
                arg_is_id = isinstance( i, int)
                sub_ctrl.jobs.lock.acquire()
                ij = 0
                while (ij < len( sub_ctrl.jobs.all)):
                    job = sub_ctrl.jobs.all[ij]
                    remove = False
                    if (job.status > 1):
                        remove = arg_is_id and i == job.ID
                        remove = remove or not( arg_is_id) and i == 'all'
                        remove = remove or not( arg_is_id) and i == job_status[job.status]
                        if (remove):
                            sub_ctrl.jobs.all.remove( job)
                            n_jobs += 1
                    if (not( remove)):
                        ij += 1
                sub_ctrl.jobs.lock.release()

            if (n_jobs):
                plural = get_plural( ('job', 'jobs'), n_jobs)
                msg = plural[1] + ' finished ' + plural[0] + ' removed.\n'
            else:
                msg = 'Nothing to do: required jobs not found.\n'
            client_master.send( msg)

        else:
            client_master.send( 'Unknown option: ' + str( job_type) + '\n')

if (ini_job_ID == None):
    try:
        f = open( jobID_file, 'r')
        ini_job_ID = int( f.read())
        f.close()
    except:
        sys.exit( 'Problem to get initial jobID. Please, report this bug.')

sub_ctrl = submission_control()
sub_ctrl.start()

handle_client( sub_ctrl, ini_job_ID)
os.remove( port_file)

if (verbose):
    print "qpy-master: done!"
