#!/usr/bin/python
# qpy-master - set the main driver for qpy
#
# 29 May 2015 - Pradipta and Yuri
from multiprocessing.connection import Listener
from multiprocessing.connection import Client
import threading
from time import sleep
from Queue import Queue
import re
import subprocess
import sys
import os
import random

home_dir = os.environ['HOME']
queue_dir = home_dir + '/Codes/queue_hlrs'

random.seed()
#port = 16000# random.randint( 10000, 20000 )
port = random.randint( 10000, 20000 )
f_port = open(queue_dir + '/.port', 'w', 0)
f_port.write( str( port))
f_port.close()

def node_alloc():
    queue_script = 'qpy --alloc'
    command = 'salloc -N1 -t 21-0 -K -A ithkoehn ' + queue_script + ' &'
    salloc = subprocess.Popen(command,
                              shell=True,
                              stdout=subprocess.PIPE,
                              stderr=subprocess.PIPE)
    salloc_stderr = salloc.stderr.readline()
    re_res = re.match('salloc: Granted job allocation (\d+)', salloc_stderr)
    job_id = re_res.group(1)
    command = 'squeue | grep ' + job_id
    squeue = subprocess.Popen(command,
                              shell=True,
                              stdout=subprocess.PIPE,
                              stderr=subprocess.PIPE)
    saloc_stdout = squeue.stdout.readline().split()
    node = saloc_stdout[-1]

    init_script = 'source ~/.bash_profile; qpy --init'
    alloc = subprocess.Popen(["ssh", "-o", "StrictHostKeyChecking=no", node, init_script],
                             shell=False,
                             stdout=subprocess.PIPE,
                             stderr=subprocess.PIPE)

    print "Node_alloc init_q stdout: ", alloc.stdout.readlines()
    print "Node_alloc init_q stderr: ", alloc.stderr.readlines()
    
    return (job_id, node)


def node_dealloc( node_id, alloc_id):
    term_script = 'source ~/.bash_profile; qpy --term'
    dealloc = subprocess.Popen(["ssh", "-o", "StrictHostKeyChecking=no", node_id, term_script],
                               shell=False,
                               stdout=subprocess.PIPE,
                               stderr=subprocess.PIPE)
    print "node_dealloc stdout: ", dealloc.stdout.readlines()
    print "node_dealloc stderr: ", dealloc.stderr.readlines()

    command = 'scancel ' + alloc_id
    dealloc = subprocess.call( command, shell=True)

# Check output
#
class out_err_check( threading.Thread):
    
    def __init__( self, ssh, out_or_err, out_err_file):
        threading.Thread.__init__( self)
        self.ssh = ssh
        self.out_or_err = out_or_err
        self.file = out_err_file
        self.file_lock = threading.RLock()

    def run( self):

        if (self.out_or_err):
            for c in iter( lambda: self.ssh.stdout.read(1), ''):
                self.file_lock.acquire()
                self.file.write(c)
                self.file_lock.release()
        else:
            for c in iter( lambda: self.ssh.stderr.read(1), ''):
                self.file_lock.acquire()
                self.file.write(c)
                self.file_lock.release()

    
# Job sender - send a job to a node
#
class job_send( threading.Thread):
    
    def __init__( self, node, job, jobID):
        threading.Thread.__init__( self)
        self.node = node
        self.job = job
        self.jobID = jobID
        self.err_msg = ''

    def run( self):
        command = 'source ~/.bash_profile; cd ' + self.job[1] + '; ' + self.job[0]
        ssh = subprocess.Popen(["ssh", self.node, command],
                               shell=False,
                               stdout=subprocess.PIPE,
                               stderr=subprocess.PIPE)

        f_out_err = open( self.job[1] + '/job_' + str(self.jobID) + '.outerr', 'w', 0)

        err_chk = out_err_check( ssh, False, f_out_err)
        err_chk.start()
        out_chk = out_err_check( ssh, True, f_out_err)
        out_chk.start()

        err_chk.join()
        out_chk.join()

        f_out_err.close()


# A node.
#
class node_connection( threading.Thread):

    def __init__( self, max_jobs):
        threading.Thread.__init__( self)

        new_node = node_alloc()
        self.alloc_id = new_node[0]
        self.node_id = new_node[1]

        self.max_jobs = max_jobs
        self.queue = Queue()
        self.jobs = []
        self.jobs_lock = threading.RLock()

        
    def run( self):

        while True:
            new_job = self.queue.get()

            if ( isinstance( new_job, str)):
                if ( new_job == 'kill'):
                    break

            # new_job = [<jobID>, <job_type>, <job_info>]
            j = job_send( self.node_id, new_job[2], new_job[0])
            j.start()
            self.jobs_lock.acquire()
            self.jobs.append(j)
            self.jobs_lock.release()
                
            sleep(1)

        node_dealloc( self.node_id, self.alloc_id)
        print "Node " + str( self.node_id) + ' done.'
            

# Control jobs subimission
# 
#
class submission_control( threading.Thread):
    def __init__( self):
        threading.Thread.__init__( self)
        self.live = True
        self.node_list = []
        self.max_nodes = 3
        self.max_jobs_default = 20
        self.jobs_queue = Queue()
        self.queue_lock = threading.RLock()
        self.jobs_done = []
        self.jobs_done_lock = threading.RLock()

    def run( self):
        while self.live:
            
            # Check finished jobs
            for node_c in self.node_list:
                node_c.jobs_lock.acquire()
                for running_job in node_c.jobs:
                    if (not (running_job.is_alive())):
                        self.jobs_done_lock.acquire()
                        self.jobs_done.append(running_job)
                        self.jobs_done_lock.release()
                        node_c.jobs.remove(running_job)
                node_c.jobs_lock.release()

            # Dealloc the non-used node
            for node_c in self.node_list:
                if (not( node_c.jobs)):
                    node_c.queue.put( 'kill')
                    self.node_list.remove( node_c)

            # Send a job, if there is space
            self.queue_lock.acquire()
            if (not( self.jobs_queue.empty())):
                best_free = 0
                best_node = None
                for node_c in self.node_list:
                    free = node_c.max_jobs - len(node_c.jobs)
                    if (free > best_free):
                        best_node = node_c
                        best_free = free
                if (best_node == None and len( self.node_list) < self.max_nodes):
                    best_node = node_connection( self.max_jobs_default)
                    best_node.start()
                    sub_ctrl.node_list.append( best_node)
                if (best_node != None):
                    best_node.queue.put( self.jobs_queue.get())

            self.queue_lock.release()

            sleep(1)

# formating a list of jobs
def format_jobs(jobs_list):
    jobs = ''
    for j in jobs_list:
        jobs += str( j.jobID) + ':' + j.job[0] + ' (wd: ' + j.job[1] + ')\n';

    return jobs

# return string with current jobs
def get_cur_jobs( sub_ctrl):
    nd_jobs = ''
    cur_jobs = ''

    sub_ctrl.queue_lock.acquire()
    n_q = sub_ctrl.jobs_queue.qsize()
    for i in range( 0, n_q):
        j = sub_ctrl.jobs_queue.get()
        nd_jobs += str( j[0]) + ':' + j[2][0] + ' (wd: ' + j[2][1] + ')\n';
        sub_ctrl.jobs_queue.put( j)
    sub_ctrl.queue_lock.release()

    if (nd_jobs):
        cur_jobs += 'Queue' + ':\n' + nd_jobs

    for node in sub_ctrl.node_list:
        nd_jobs = format_jobs(node.jobs)
        if (nd_jobs):
            cur_jobs += node.node_id + ':\n' + nd_jobs
    return cur_jobs


# Get job from client and send it for submission
# message from client must be:
#   (job_type, job)
# where:
#   job_type is
#       1 - submit a job     (sub)
#       2 - check the jobs   (check)
#       3 - kill a job       (kill)
#       4 - kill the master  (finish)
#       5 - change max_nodes (nodes)
#       6 - change max_jobs  (njobs)
#       7 - show config      (config)
#       8 - show jobs done   (done)
#              
#   job is a list with the job informations
#
def handle_client( sub_ctrl, jobId):
    print "queue_master_driver: ready"
    server_master = Listener(( "localhost", port), authkey = 'qwerty')
    while True:
        client_master = server_master.accept()
        (job_type, job) = client_master.recv()

        # Send a job
        if (job_type == 1):
            sub_ctrl.queue_lock.acquire()
            sub_ctrl.jobs_queue.put( (jobId, job_type, job))
            sub_ctrl.queue_lock.release()
            jobId += 1
            client_master.send( 'Job received.\n')

        # Check jobs
        elif (job_type == 2):
            client_master.send( get_cur_jobs( sub_ctrl))

        # Kill a job
        elif (job_type == 3):
#            for i in job:
#                kill i
            client_master.send( 'Killing job: not implemented.\n')

        # Finish the master execution
        if (job_type == 4):
            if (sub_ctrl.node_list or not( sub_ctrl.jobs_queue.empty())):
                client_master.send( 'There are unfinished jobs.\n')
            else:
                client_master.send( 'Stopping master driver.\n')
                sub_ctrl.live = False
                break

        # Change maximum number of nodes
        elif (job_type == 5):
            sub_ctrl.max_nodes = job
            client_master.send( 'Maximum number of nodes changed to ' + str( job) + '.\n')

        # Change maximum number of jobs
        elif (job_type == 6):
            sub_ctrl.max_jobs_default = job
            for n in sub_ctrl.node_list:
                n.max_jobs = sub_ctrl.max_jobs_default
            client_master.send( 'Maximum number of jobs changed to ' + str( job) + '.\n')

        # Show current configuration
        elif (job_type == 7):
            cur_conf = ''
            cur_conf += 'max_jobs  = ' + str( sub_ctrl.max_jobs_default) + '\n'
            cur_conf += 'max_nodes = ' + str( sub_ctrl.max_nodes) + '\n'
            client_master.send( cur_conf)

        # make a list of finished jobs
        elif (job_type == 8):
            if (job):
                sub_ctrl.jobs_done_lock.acquire()
                for i in job:
                    for j in sub_ctrl.jobs_done:
                        if (i == j.jobID):
                            sub_ctrl.jobs_done.remove(j)
                            break 
                sub_ctrl.jobs_done_lock.release()
                client_master.send( str(len(job)) + ' jobs are removed \n')
            else:
                cur_jobs = ''
                sub_ctrl.jobs_done_lock.acquire()
                jobs = format_jobs(sub_ctrl.jobs_done)
                sub_ctrl.jobs_done_lock.release()
                if (jobs):
                    cur_jobs += 'finished jobs' + ':\n' + jobs
                client_master.send(cur_jobs)

        else:
            client_master.send( 'Unknown option: ' + str( job_type) + '\n')


sub_ctrl = submission_control()
sub_ctrl.start()
handle_client( sub_ctrl, 1)
print "queue_master_driver: done!"
